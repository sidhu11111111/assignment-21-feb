{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63b192a4-5b6e-4d7a-bfd9-b8cca7ce08fe",
   "metadata": {},
   "source": [
    "#QNO.1 ANS\n",
    "Web scraping is the process of extracting and collecting data from websites automatically using a software tool or a script. The data could be in different formats such as text, images, videos, tables, and more. Web scraping can be performed using programming languages like Python, R, and JavaScript.\n",
    "\n",
    "USE OF WEB SRAPPING:\n",
    "Web scapping is used in data minning, market research, competitive analysis, lead generation, price monitring, \n",
    "and web scrapping is fast process it saves our time.\n",
    "\n",
    "THRE AREAS WHERE WEB SCRAPPING IS USED TO GET DATA ARE:\n",
    "1.E-commerce\n",
    "2.Finance\n",
    "3.Research"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "060c0c58-a1d5-4203-b0ba-f3e0a47df412",
   "metadata": {},
   "source": [
    "#QNO.2 ANS\n",
    "The different methods we used Web scrapping are dependending on the type of data to be extracted and the complexicity of the website being scraped.\n",
    "\n",
    "1.Using Web Scrapping Tools:There are many web scraping tools available in the market like Scrapy, BeautifulSoup, Selenium, and more.\n",
    "\n",
    "2.API Scraping: Many websites offer APIs (Application Programming Interfaces) that allow developers to access their data in a structured format. API scraping involves making requests to these APIs and extracting the data in a structured format.\n",
    "\n",
    "3.Parsing HTML/XML: HTML and XML parsing involves extracting data from the HTML or XML markup of a webpage. This method requires an understanding of HTML and XML markup languages and how they are used to structure content on the web."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd28dd0-c41f-4c03-aaa5-98f39475e92c",
   "metadata": {},
   "source": [
    "#QNO.3 ANS\n",
    "Beautiful Soup is a Python library that is used for web scraping purposes. It is a powerful tool for extracting data from HTML and XML documents. Beautiful Soup parses the HTML/XML content and provides a simple and flexible way to navigate and search the HTML/XML tree structure, making it easier to extract the required data from web pages.\n",
    "\n",
    "we used Beautiful Soup because it provides a variety of useful functions for working with HTML and XML documents. It enables developers to parse HTML/XML documents, navigate the document tree, and search for specific elements and attributes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ea3b45-99b4-437d-8935-753f1d2f17cd",
   "metadata": {},
   "source": [
    "#QNO.4 ANS\n",
    "Flask is used in Web Scrapping because it is lightweight and easy to use. Flask is often used in web scraping projects because it provides a convenient way to build web interfaces that can interact with the scraped data.\n",
    "\n",
    "it also easy to interact with other libraraies."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ffc5e6-3c13-446c-a299-5d32a3b1953c",
   "metadata": {},
   "source": [
    "#QNO.5 ANS\n",
    "There are several AWS service used in project like:\n",
    "\n",
    "1.Amazon EC2: EC2 (Elastic Compute Cloud) is a scalable cloud computing service that provides virtual servers (instances) that can be used to run web scraping scripts. EC2 is used to launch and manage virtual servers that run the web scraping script, enabling developers to scale up or down the computing resources as needed.\n",
    "\n",
    "2.Amazon S3: S3 (Simple Storage Service) is a scalable and durable object storage service that can be used to store the scraped data. S3 is used to store the data that is extracted from the web scraping script, making it easy to access and analyze the data later on.\n",
    "\n",
    "3.Amazon RDS: RDS (Relational Database Service) is a scalable cloud database service that can be used to store structured data. RDS is used to store the scraped data in a structured format, enabling developers to query and analyze the data using SQL.\n",
    "\n",
    "4.Amazon Lambda: Lambda is a serverless computing service that can be used to run the web scraping script in response to events. Lambda is used to execute the web scraping script in a serverless environment, enabling developers to scale the computing resources based on the demand.\n",
    "\n",
    "5.Amazon SQS: SQS (Simple Queue Service) is a managed message queue service that can be used to decouple and scale microservices, distributed systems, and serverless applications. SQS is used to decouple the web scraping script from the downstream data processing services, ensuring that the scraped data is delivered reliably and at scale.\n",
    "\n",
    "6.Amazon CloudWatch: CloudWatch is a monitoring service that can be used to monitor the performance of the web scraping script and the infrastructure. CloudWatch is used to monitor the logs, metrics, and alarms related to the web scraping script, enabling developers to detect and diagnose issues quickly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
